# -*- coding: utf-8 -*-
"""finalni kod trueaid

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-bWZWrZ7z6TlN5As4kFaBhm9EcSSlXN
"""

# -*- coding: utf-8 -*-
import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.image as mpimg
import keras
import tensorflow as tf
from google.colab import drive
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.utils.class_weight import compute_sample_weight
from sklearn.utils import class_weight

#Ucitavanje slika
drive.mount('/content/drive')
data_dir=r'/content/drive/MyDrive/DOKTORAT IBU/Thesis/DATA/Training slike'
img_height, img_width = 512,512
batch_size = 16
first_level_classes = ['Face', 'Hand to face', 'Legs', 'Thumb']
num_classes=len(first_level_classes)

#Definicija modela
def create_model(num_classes):
    model = Sequential([
        Conv2D(16, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
        MaxPooling2D(2, 2),
        Conv2D(32, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

model = create_model(num_classes)

#Generatori
datagen=ImageDataGenerator(
    rescale=1. / 255,
    rotation_range=90,  # rotation
    horizontal_flip=True,  # horizontal flip
    vertical_flip= True,  # vertical flip
    validation_split=0.2
)

train_generator =datagen.flow_from_directory(data_dir, target_size=(img_height, img_width),
                                            batch_size=batch_size, class_mode='categorical',
                                            classes=first_level_classes, subset='training')
val_generator = datagen.flow_from_directory(data_dir, target_size=(img_height, img_width),
                                            batch_size=batch_size, class_mode='categorical',
                                            classes=first_level_classes, subset='validation')

#optimizacija i hiperparametri
#train_labels = train_generator.classes
#class_weights = compute_sample_weight(class_weight='balanced', y=train_labels)
#class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}
#lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)

# Define your manual class weights
manual_class_weights = {0: 1.5, 1: 1.0, 2: 1.0, 3: 1.0}  # Adjust weights as needed

# Ensure the dictionary includes all class indices
train_labels = train_generator.classes
unique_classes = np.unique(train_labels)

# Create a dictionary mapping each class to its corresponding weight
class_weights_dict = {cls: manual_class_weights.get(cls, 1.0) for cls in unique_classes}

# Define learning rate scheduler
lr_scheduler = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2)

# Trening
model = create_model(num_classes)

history1 = model.fit(train_generator,
                     validation_data=val_generator,
                     class_weight=class_weights_dict,
                     callbacks=[lr_scheduler],
                     epochs=30)
model.save(r'/content/drive/MyDrive/DOKTORAT IBU/Thesis/novimodel2803.h5')
history_df = pd.DataFrame(history1.history)
history_df.to_csv(r'/content/drive/MyDrive/DOKTORAT IBU/Thesis/novimodel2803.csv')


#Plot trening historije
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history1.history['accuracy'], label='Train Accuracy')
plt.plot(history1.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history1.history['loss'], label='Train Loss')
plt.plot(history1.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()

plt.tight_layout()
plt.show()

#Interna validacija
y_true = val_generator.classes
y_pred_probs = model.predict(val_generator)
y_pred = np.argmax(y_pred_probs, axis=1)

#Confusion matrix
cm = confusion_matrix(y_true, y_pred)
cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
plt.figure(figsize=(10,10))
sns.heatmap(cm, annot=True, fmt=".2f", linewidths=.5, square = True, cmap = 'Blues')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.title('Confusion Matrix', size = 15)
plt.show()

#Subsequent validacija

#Ucitavanje slika i modela
model = load_model(r'/content/drive/MyDrive/DOKTORAT IBU/Thesis/novimodel2803.h5')
test_images_dir = r'/content/drive/MyDrive/DOKTORAT IBU/Thesis/DATA/Validacija2'

processed_images = []
true_labels = []
class_names = sorted(os.listdir(test_images_dir))
for class_name in class_names:
    class_dir = os.path.join(test_images_dir, class_name)
    for filename in os.listdir(class_dir):
        if filename.endswith('.jpg') or filename.endswith('.png'):
            image_path = os.path.join(class_dir, filename)
            img = cv2.imread(image_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB format
            img = cv2.resize(img, (512, 512))  # Resize to match your model's input size
            img = img / 255.0  # Normalize pixel values to the range [0, 1]
            processed_images.append(img)
            true_labels.append(class_name)
processed_images = np.array(processed_images)

# Predikcije
predictions = model.predict(processed_images)
predicted_labels = np.argmax(predictions, axis=1)
label_encoder = LabelEncoder()
true_labels_encoded = label_encoder.fit_transform(true_labels)

#Plotovi i kalkulacije rezultata
confusion_mat = confusion_matrix(true_labels_encoded, predicted_labels)
sensitivity = []
specificity = []
f1_score = []
accuracy = []
mcc = []
for i in range(len(class_names)):
    true_positive = confusion_mat[i, i]
    false_positive = confusion_mat[:, i].sum() - true_positive
    false_negative = confusion_mat[i, :].sum() - true_positive
    true_negative = confusion_mat.sum() - (true_positive + false_positive + false_negative)

    sensitivity_i = true_positive / (true_positive + false_negative)
    specificity_i = true_negative / (true_negative + false_positive)
    precision_i = true_positive / (true_positive + false_positive)
    recall_i = sensitivity_i
    f1_score_i = 2 * (precision_i * recall_i) / (precision_i + recall_i)
    accuracy_i = (true_positive + true_negative) / confusion_mat.sum()
    mcc_i = (true_positive * true_negative - false_positive * false_negative) / np.sqrt(
        (true_positive + false_positive) * (true_positive + false_negative) * (true_negative + false_positive) * (
                    true_negative + false_negative))

    sensitivity.append(sensitivity_i)
    specificity.append(specificity_i)
    f1_score.append(f1_score_i)
    accuracy.append(accuracy_i)
    mcc.append(mcc_i)

plt.figure(figsize=(10, 8))
plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.get_cmap('Blues'))
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=45)
plt.yticks(tick_marks, class_names)

# Add labels to each cell
for i in range(len(class_names)):
    for j in range(len(class_names)):
        plt.text(j, i, str(confusion_mat[i, j]), horizontalalignment='center', verticalalignment='center')

plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()


for i, class_name in enumerate(class_names):
    print(f'Class: {class_name}')
    print(f'Sensitivity: {sensitivity[i]:.2f}')
    print(f'Specificity: {specificity[i]:.2f}')
    print(f'F1 Score: {f1_score[i]:.2f}')
    print(f'Accuracy: {accuracy[i]:.2f}')
    print(f'MCC: {mcc[i]:.2f}')
    print('-' * 20)

class_report = classification_report(true_labels, predicted_labels, target_names=class_names)
print(class_report)